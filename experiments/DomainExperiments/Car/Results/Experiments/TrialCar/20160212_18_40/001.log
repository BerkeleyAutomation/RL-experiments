     0: >>>Eps 0: Return=    -3.115, Steps=43.65, Features = 0, Learning Rate=0.3
   500: >>>Eps 10: Return=        -5, Steps=50.0, Features = 224, Learning Rate=0.3
  1000: >>>Eps 20: Return=        -5, Steps=50.0, Features = 363, Learning Rate=0.3
  1491: >>>Eps 30: Return=        -5, Steps=50.0, Features = 483, Learning Rate=0.3
  1991: >>>Eps 40: Return=        -5, Steps=50.0, Features = 562, Learning Rate=0.3
  2491: >>>Eps 50: Return=        -5, Steps=50.0, Features = 641, Learning Rate=0.3
  2989: >>>Eps 60: Return=    -3.145, Steps=48.95, Features = 696, Learning Rate=0.3
  3489: >>>Eps 70: Return=        -5, Steps=50.0, Features = 766, Learning Rate=0.3
  3983: >>>Eps 80: Return=        -5, Steps=50.0, Features = 835, Learning Rate=0.3
  4483: >>>Eps 90: Return=        -5, Steps=50.0, Features = 922, Learning Rate=0.3
  4983: >>>Eps 100: Return=        -5, Steps=50.0, Features = 950, Learning Rate=0.3
  5451: >>>Eps 110: Return=        -5, Steps=50.0, Features = 1006, Learning Rate=0.3
  5951: >>>Eps 120: Return=        -5, Steps=50.0, Features = 1091, Learning Rate=0.3
  6451: >>>Eps 130: Return=        -5, Steps=50.0, Features = 1105, Learning Rate=0.3
  6951: >>>Eps 140: Return=        -5, Steps=50.0, Features = 1164, Learning Rate=0.3
  7451: >>>Eps 150: Return=       3.1, Steps=19.0, Features = 1230, Learning Rate=0.3
  7951: >>>Eps 160: Return=        -5, Steps=50.0, Features = 1285, Learning Rate=0.3
  8420: >>>Eps 170: Return=        -5, Steps=50.0, Features = 1318, Learning Rate=0.3
  8890: >>>Eps 180: Return=        -5, Steps=50.0, Features = 1360, Learning Rate=0.3
  9362: >>>Eps 190: Return=        -5, Steps=50.0, Features = 1392, Learning Rate=0.3
  9835: >>>Eps 200: Return=      -3.5, Steps=45.0, Features = 1451, Learning Rate=0.3
 10335: >>>Eps 210: Return=     -1.58, Steps=38.3, Features = 1503, Learning Rate=0.3
 10745: >>>Eps 220: Return=        -5, Steps=50.0, Features = 1535, Learning Rate=0.3
 11245: >>>Eps 230: Return=        -5, Steps=50.0, Features = 1595, Learning Rate=0.3
 11705: >>>Eps 240: Return=       2.5, Steps=25.0, Features = 1651, Learning Rate=0.3
 12186: >>>Eps 250: Return=        -5, Steps=50.0, Features = 1694, Learning Rate=0.3
 12686: >>>Eps 260: Return=        -5, Steps=50.0, Features = 1736, Learning Rate=0.3
 13163: >>>Eps 270: Return=        -5, Steps=50.0, Features = 1767, Learning Rate=0.3
 13663: >>>Eps 280: Return=        -5, Steps=50.0, Features = 1822, Learning Rate=0.3
 14146: >>>Eps 290: Return=        -5, Steps=50.0, Features = 1845, Learning Rate=0.3
 14646: >>>Eps 300: Return=       2.7, Steps=23.0, Features = 1882, Learning Rate=0.3
 15119: >>>Eps 310: Return=        -5, Steps=50.0, Features = 1896, Learning Rate=0.3
 15586: >>>Eps 320: Return=       1.8, Steps=32.0, Features = 1912, Learning Rate=0.3
 16075: >>>Eps 330: Return=       2.4, Steps=26.0, Features = 1926, Learning Rate=0.3
 16523: >>>Eps 340: Return=        -5, Steps=50.0, Features = 1940, Learning Rate=0.3
 17015: >>>Eps 350: Return=       2.5, Steps=25.0, Features = 1973, Learning Rate=0.3
 17512: >>>Eps 360: Return=       1.8, Steps=32.0, Features = 1982, Learning Rate=0.3
 17990: >>>Eps 370: Return=        -5, Steps=50.0, Features = 1994, Learning Rate=0.3
 18473: >>>Eps 380: Return=        -5, Steps=50.0, Features = 2004, Learning Rate=0.3
 18933: >>>Eps 390: Return=        -5, Steps=50.0, Features = 2017, Learning Rate=0.3
 19338: >>>Eps 400: Return=        -5, Steps=50.0, Features = 2034, Learning Rate=0.3
Total Experiment Duration 0:03:59
